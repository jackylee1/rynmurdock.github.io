# ACCNs and Accents

>After reading about [Dimensions of Dialogue](https://www.joelsimon.net/dimensions-of-dialogue.html) 
and [GlyphNet](https://github.com/noahtren/GlyphNet), 
>I decided to investigate the idea of two artificial neural networks (NNs) communicating over a noisy channel.
>The idea is to have an arbitrary number of classes that serve as content to be communicated effectively between an observer and speaker,
all with the chance of some of the information in the communication to be lost.

In my [previous post](https://rynmurdock.github.io/2020/02/05/CCN.html) on Cooperative Communication Networks (which you should
probably read for background before reading this), I mentioned adversarial interference as a possible way to move forward
with this work. What if, instead of adding random noise, a neural network could try to interfere with the efforts
of the two communicating networks to recover their label? This network would take in the original image and then generate another
image, which would then be added to the original in between the two cooperating neural networks. There's no reason to use silly,
random additive noise when you can have a semi-intelligent system do it for you!

The idea of adding the adversarial agent's image was thought up by [noahtren](https://twitter.com/noahtren) during our
correspondence, and I implemented it. I would share the notebook, but it was made in kaggle, and for some reason even I can't
access it or a GPU to run it. Oh well. 

So, were the results from these Adversarial-Cooperative Communication Networks (our titular ACCN) the same 
as adding random noise? 
No - in fact, I think the differences are surprising!

One aspect of the original CCN that I failed to mention in the first post (Oh well.) is that the two communicating networks
eventually converged. Not only were their representations reminiscent of human writing, but they also were the same or very 
similar across networks. For instance: 



![S-like image](/images/s0.png)


![S-like as well, but with small difference](/images/s1.png)

These are two "S"-esque images generated by two networks using random noise. Obviously they are very similar; they are also
representative of other glyphs produced in these networks that all tend towards matching as the communicators 
converge on a "common language" of (very simplified) sorts.

But contrast this with the following four images: 

![black and white image](/images/acc0.png)
![black and white image](/images/acc2.png)
![black and white image](/images/acc1.png)
![black and white image](/images/acc3.png)

I'm guessing you can tell which images were created by the same model. It's as if each model has a unique accent, forced
as an attempt to overcome the adversarial agent. My running guess is that blocky, thin shapes cannot be blocked by large blobs,
and large blobs cannot be blocked by blocky, thin shapes. This means that at least some of the signal will go through when 
attempting to minimize misinterpretation between the two cooperators - even if one NN is unable to communicate over the 
interference, they lower their collective loss by getting the other's message through. 

So, what's next for CCNs? Quite a bit, actually. CPPNs, audio, large batch sizes, man-in-the-middle attacks, and 
probably even more if I don't make it into grad school.
